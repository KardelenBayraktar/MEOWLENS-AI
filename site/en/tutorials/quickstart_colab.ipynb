{
  "cells": [
    {
      "source": [
        "!pip install tensorflow==2.12.0\n",
        "!pip install keras==2.12.0\n",
        "!pip install opencv-python\n",
        "!pip install Pillow"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Umie5Wudfltw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!unzip images.zip"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "e_AgvbGzfvXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "v57cviDdGjMV"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "source": [
        "train_data_dir = '/content'  # 'content' yerine gerçek dizini kullanın\n",
        "img_width, img_height = 150, 150\n",
        "batch_size = 32\n",
        "\n",
        "# Veri artırma için ImageDataGenerator kullanın\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Eğitim ve doğrulama veri kümelerini oluşturun\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,  # Güncellenmiş dizin\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,  # Güncellenmiş dizin\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "99_gy9YVHSTx",
        "outputId": "55adfde8-3eb3-471f-fa88-3d10ee764900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 101313 images belonging to 70 classes.\n",
            "Found 25294 images belonging to 70 classes.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(train_generator.num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "uLM9IsNhHqy7"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "source": [
        "# ... (model tanımlaması) ...\n",
        "\n",
        "# Modeli derleme\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Modeli eğitme\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // batch_size\n",
        ")\n",
        "\n",
        "# ... (diğer kodlar) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "WimC2-qKLo5_",
        "outputId": "a68ba96c-d380-454c-a1af-609d11736eaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3166/3166 [==============================] - 6641s 2s/step - loss: 2.6925 - accuracy: 0.4181 - val_loss: 2.5496 - val_accuracy: 0.4193\n",
            "Epoch 2/10\n",
            "3166/3166 [==============================] - 6612s 2s/step - loss: 2.5700 - accuracy: 0.4187 - val_loss: 2.4689 - val_accuracy: 0.4194\n",
            "Epoch 3/10\n",
            " 384/3166 [==>...........................] - ETA: 1:28:04 - loss: 2.5444 - accuracy: 0.4107"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "quickstart_colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}